{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Меня зовут Сергей Казьмин\n",
    "### Моя версия Python: 3.6.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ---------------------------------------------------------UPDATE---------------------------------------------------------\n",
    "###### Мне сообщили о следующих замечаниях:\n",
    "1. Не учтены запросы латиницей русскими (изначальна подразумевалась разбивка по языку девайса, указанному в столбце locale)\n",
    "\n",
    "2. Невозможно масштабирование на большее количество языков, нужно учесть такую возможность. \n",
    "\n",
    "3. В результат необходимо добавить количество запросов (достопримечательность - 5000, где поесть - 4000 и т.д.)\n",
    "\n",
    "4. В реальности нет возможности загрузить весь датасет в память и обработка ведётся последовательно событие за событием. Как изменится реализация? \n",
    "\n",
    "5. Опционально: Исключить из общего списка запросы по категориям и вывести их отдельно. Найти их можно в приложении в поиске на вкладке «категории». Чтобы посмотреть как они выглядят на английском, необходимо сменить язык телефона на английский и перезапустить приложение. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 пункт\n",
    "Я недопонял, надо ли мне в этом пункте что-то исправлять в коде или просто нужно ответить на вопрос словами :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я напишу свои мысли, как это реализовать. Если вдруг надо было писать код - пожалуйста, сообщите мне."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак\n",
    "- Если памяти не хватает под весь датасет, то можно, во-первых, воспользоваться параметром chunksize функции pandas.read_csv, принцип работы с датасетом не изменится, мы просто будем итерироваться по chunk-ам и проделывать аналогичные действия. \n",
    "- Другой вариант заключается в следующем. В моих циклах for мы обычно сравниваем только i и i+1 события, после чего решаем оставить событие i в датасете или исключить его. Причём сохраняем именно индекс, который занимает мало памяти. То есть на каждой итерации нам достаточно хранить в памяти i и i+1 события. Можно читать из файла построчно, открывать это всё в pandas, т.е. будет dataframe из 2 строк, проводить их сравнение и оставлять индекс. Потом по индексам выгружать необходимые события, делать из них словарь частоты встречаемости. ГЛАВНОЕ, надо просто получить первичный словарь встречаемости, например, такой же, какой я получаю в конце этого скрипта. После того, как сделан этот первый словарь, действия такие:\n",
    "    1. i запрос получен, получаем i+1\n",
    "    2. если i+1 стал короче, чем i, то берём i запрос (это алгоритм, до которого додумался я :) ) \n",
    "    3. теперь ищем в нашем словаре встречаемости ключ, максимально похожий по метрике Джаро-Винклера на i-ый запрос и увеличиваем значение по этому ключу на единицу. (Можно попробовать ускорить это, начиная искать не среди всех ключей, а среди ключей с большой частотой встречаемости).\n",
    "    4. Если не нашли достаточно похожтй ключ (надо установить порог, начиная с которого можно считать похожими), то добавляем новый ключ со значением 1.\n",
    "    5. В итоге наш словарь встречаемости будет отражать текущую ситуацию популярных запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Я внёс исправления, прокомментирую по пунктам\n",
    "\n",
    "1. Сделал разбивку по столбцу locale - теперь словарь встречаемости выглядит так (query, language):frequency\n",
    "2. Теперь можно отмасштабировать на большее количество языков, просто будем добавлять больше меток в словарь встречаемоcти\n",
    "3. Добавил в результат количество запросов\n",
    "4. Выше \n",
    "5. Добавил после первых двух исходных ТОПов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ----------------------------------------------------UPDATE ENDED----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Сначала опишу задание так, как я его понял.\n",
    "В датасете собраны логи действий юзера при набирании запроса, например:\n",
    "0. п\n",
    "1. пр\n",
    "2. про\n",
    "3. прод\n",
    "4. ...\n",
    "7. продукты\n",
    "\n",
    "Здесь запрос пользователя - это слово \"продукты\", в то время как \"п\", \"пр\", \"про\", \"прод\", ... - это побочная информация. \n",
    "#### Моя цель в следующем: выделить в логах из действий пользователя конкретный запрос и сформировать ТОП.\n",
    "В случае моего примера из всех данных о вводе запроса надо выделить строку, в которой написано \"продукты\".\n",
    "Чтобы выделять отдельные запросы следует подготовить данные. Стоит отметить, что определённая погрешность присутствует в любом моём действии с данными, но, если учесть, что датасет очень велик, в конце должен получиться достаточно достоверный результат.\n",
    "\n",
    "### Закономерности, которые я буду использовать при обработке датасета\n",
    "1. Если идти по колонке query сверху вниз, длина слов, набранных пользователем, сначала возрастает, потом достигает максимальной длины, когда это ЗАПРОС пользователя и потом либо убывает, либо вообще начинаются данные о запросе другого юзера.\n",
    "2. Продолжительность набора запроса пользователем примерно 2-8 секунд, следовательно, можно группировать данные по id юзера и по интервалу времени 7-10 секунд. Получив интервал, можно выбрать из него слово, максимальное по длине, и с большой вероятностью оно окажется искомым запросом.\n",
    "\n",
    "### Время, за которое скрипт обрабатывает данные ~ 50 минут на моём ноутбуке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 22414: expected 5 fields, saw 6\\nSkipping line 33796: expected 5 fields, saw 6\\nSkipping line 33797: expected 5 fields, saw 6\\nSkipping line 33798: expected 5 fields, saw 6\\nSkipping line 36710: expected 5 fields, saw 6\\n'\n",
      "b'Skipping line 922233: expected 5 fields, saw 6\\n'\n",
      "b'Skipping line 3615615: expected 5 fields, saw 6\\n'\n",
      "b'Skipping line 4153368: expected 5 fields, saw 6\\nSkipping line 4153369: expected 5 fields, saw 6\\nSkipping line 4153370: expected 5 fields, saw 6\\n'\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"raw_search_data.csv\", sep=';', error_bad_lines=False) \n",
    "#Ошибки возникают с длинными запросами, в которых встречаются кавычки и точки с запятыми, очевидно, \n",
    "#таких запросов немного, проигнорировать можно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Убираем все строки, в которых есть незаполненные столбцы. Их немного, не сильно повлияет на результат\n",
    "data = data.dropna() \n",
    "\n",
    "data['query'] = data['query'].apply(lambda x: str(x).lower()) \n",
    "\n",
    "#Игнорируем запросы длиннее 50 символов, таких всего ~10000\n",
    "data = data[list(map(lambda x: len(x) < 50, data[:]['query']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем дату-время из строки в datetime\n",
    "data['datetime'] = data['datetime'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_for_save = []\n",
    "#Алгоритм, отбрасывающий больше 50% данных о том, как пользователи вводили запрос. \n",
    "#Пока длина запроса увеличивается ничего не делаем. \n",
    "#Как только в следующей строке лога длина запроса уменьшилась - сохраняем индекс \"локального максимума\" длины запроса.\n",
    "#Алгоритм позволяет отбросить большую часть промежуточных запросов и оставить только конечные.\n",
    "for i in range(data.shape[0] - 1):\n",
    "    if len(str(data.iloc[i+1]['query'])) <= len(str(data.iloc[i]['query'])):\n",
    "        idxs_for_save.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data.iloc[idxs_for_save]\n",
    "\n",
    "#Удаляем запросы длиной не больше 3 символов\n",
    "filtered_data = filtered_data[filtered_data[:]['query'].apply(lambda x: len(x)) > 2]\n",
    "\n",
    "filtered_data = filtered_data.reset_index()\n",
    "filtered_data = filtered_data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция сравнивает две строки метрикой Джаро-Винклера\n",
    "#Выдаёт True, если значение метрики больше или равно порога limit, False иначе\n",
    "def check_string_similarity(str_1, str_2, limit):\n",
    "    return jellyfish.jaro_winkler(str_1, str_2) >= limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_for_delete = []\n",
    "#Алгоритм сравнивает две соседние строчки в логе\n",
    "#Если это запросы от одного юзера, и они были отправлены в интервале 5 секунд, и при этом они сильно похожи по нашей метрике\n",
    "#То это один и тот же запрос => можно удалить данные об одном из них\n",
    "for i in range(filtered_data.shape[0] - 1):\n",
    "    if filtered_data.iloc[i]['uid'] == filtered_data.iloc[i+1]['uid'] and \\\n",
    "            (max(filtered_data.iloc[i]['datetime'], filtered_data.iloc[i+1]['datetime']) - \\\n",
    "            min(filtered_data.iloc[i]['datetime'], filtered_data.iloc[i+1]['datetime'])) < datetime.timedelta(seconds=5) and \\\n",
    "            check_string_similarity(filtered_data.iloc[i]['query'], filtered_data.iloc[i+1]['query'], 0.93):\n",
    "        \n",
    "        if len(filtered_data.iloc[i]['query']) <= len(filtered_data.iloc[i+1]['query']):\n",
    "            idxs_for_delete.append(i)\n",
    "        else:\n",
    "            idxs_for_delete.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_for_delete = sorted(list(set(idxs_for_delete)))\n",
    "filtered_data = filtered_data.drop(index=idxs_for_delete)\n",
    "filtered_data = filtered_data.reset_index()\n",
    "filtered_data = filtered_data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv(\"filtered_data.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_lang = []\n",
    "eng_lang = []\n",
    "\n",
    "# Сортируем все метки из locale по rus и eng\n",
    "for lang in pd.unique(filtered_data['locale']):\n",
    "    if lang[:2] == 'en' or lang[:2] == 'En':\n",
    "        eng_lang.append(lang)\n",
    "    else:\n",
    "        rus_lang.append(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем метки из locale на две ru и en \n",
    "filtered_data['locale'] = filtered_data['locale'].apply(lambda x: 'en' if x in eng_lang else 'ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список всех запросов вместе с метками\n",
    "queries_list = list(zip(filtered_data['query'], filtered_data['locale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict = {}\n",
    "#Формируем dict встречаемости запросов вместе с метками\n",
    "for query in queries_list:\n",
    "    if query not in frequency_dict.keys():\n",
    "        frequency_dict[query] = 1\n",
    "    else:\n",
    "        frequency_dict[query] += 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_more_50freq = []\n",
    "keys_more_10freq = []\n",
    "\n",
    "#Сформируем список ключей, встречающихся более 50 и 10 раз\n",
    "\n",
    "for key in frequency_dict.keys():\n",
    "    if frequency_dict[key] > 50:\n",
    "        keys_more_50freq.append(key)\n",
    "        \n",
    "for key in frequency_dict.keys():\n",
    "    if frequency_dict[key] > 10:\n",
    "        keys_more_10freq.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_for_delete = [] \n",
    "\n",
    "# Найдём среди них похожие ключи, сформируем список для удаления ключей\n",
    "for key in keys_more_50freq:\n",
    "    for key_ in keys_more_10freq:\n",
    "        if key != key_ and key[1] == key_[1] and check_string_similarity(key[0], key_[0], 0.92):\n",
    "            if frequency_dict[key] >= frequency_dict[key_]:\n",
    "                frequency_dict[key] += frequency_dict[key_] #встречаемось похожего уходит другому\n",
    "                keys_for_delete.append(key_)                #удаляется менее встречающийся ключ\n",
    "            else:\n",
    "                frequency_dict[key_] += frequency_dict[key]\n",
    "                keys_for_delete.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in set(keys_for_delete):\n",
    "    frequency_dict.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сортируем по встречаемости\n",
    "sorted_frequency = sorted(frequency_dict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_frequency = []\n",
    "eng_frequency = []\n",
    "\n",
    "#разбиваем по меткам на rus и eng\n",
    "\n",
    "for i in range(len(sorted_frequency))[::-1]:\n",
    "    if sorted_frequency[i][0][1] == 'en':\n",
    "        eng_frequency.append((sorted_frequency[i][0][0], sorted_frequency[i][1]))\n",
    "    else:\n",
    "        ru_frequency.append((sorted_frequency[i][0][0], sorted_frequency[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_rus_queries = ru_frequency[:100]\n",
    "top_100_eng_queries = eng_frequency[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП-100 запросов на русском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  достопримечательность .... 11207\n",
      "2.  где поесть ............... 10187\n",
      "3.  продукты ................. 8222\n",
      "4.  гостиница ................ 6272\n",
      "5.  заправка ................. 4261\n",
      "6.  шоппинг .................. 3109\n",
      "7.  аптека ................... 1658\n",
      "8.  транспорт ................ 1640\n",
      "9.  москва ................... 1594\n",
      "10.  банкомат ................. 1489\n",
      "11.  аэропорт ................. 1415\n",
      "12.  метро .................... 1413\n",
      "13.  минск .................... 1254\n",
      "14.  супермаркет .............. 1204\n",
      "15.  автовокзал ............... 1182\n",
      "16.  рынок .................... 1142\n",
      "17.  магазин .................. 1124\n",
      "18.  туалет ................... 1053\n",
      "19.  парковка ................. 1018\n",
      "20.  макдональдс .............. 932\n",
      "21.  улица .................... 862\n",
      "22.  банк ..................... 816\n",
      "23.  ночная жизнь ............. 795\n",
      "24.  отдых с детьми ........... 752\n",
      "25.  музей .................... 747\n",
      "26.  вокзал ................... 721\n",
      "27.  пляж ..................... 705\n",
      "28.  самара ................... 665\n",
      "29.  площадь .................. 623\n",
      "30.  развлечения .............. 595\n",
      "31.  торговый центр ........... 590\n",
      "32.  прага .................... 568\n",
      "33.  парк ..................... 561\n",
      "34.  крым ..................... 548\n",
      "35.  санкт петербург .......... 539\n",
      "36.  кафе ..................... 538\n",
      "37.  озеро .................... 533\n",
      "38.  lidl ..................... 505\n",
      "39.  киев ..................... 503\n",
      "40.  краснодар ................ 494\n",
      "41.  почта .................... 491\n",
      "42.  wifi ..................... 486\n",
      "43.  отель .................... 476\n",
      "44.  водопад .................. 462\n",
      "45.  халкидики ................ 460\n",
      "46.  волгоград ................ 455\n",
      "47.  тбилиси .................. 450\n",
      "48.  одесса ................... 450\n",
      "49.  аквапарк ................. 449\n",
      "50.  больница ................. 445\n",
      "51.  санкт .................... 443\n",
      "52.  ленина ................... 439\n",
      "53.  казань ................... 415\n",
      "54.  парикмахерская ........... 409\n",
      "55.  ростов ................... 409\n",
      "56.  воронеж .................. 406\n",
      "57.  севастополь .............. 406\n",
      "58.  варшава .................. 405\n",
      "59.  рим ...................... 394\n",
      "60.  батуми ................... 393\n",
      "61.  россия ................... 390\n",
      "62.  аланья ................... 383\n",
      "63.  ялта ..................... 382\n",
      "64.  куст ..................... 382\n",
      "65.  турция ................... 381\n",
      "66.  барселона ................ 381\n",
      "67.  калининград .............. 372\n",
      "68.  ташкент .................. 371\n",
      "69.  кирова ................... 371\n",
      "70.  зоопарк .................. 370\n",
      "71.  екатеринбург ............. 359\n",
      "72.  обмен валюты ............. 358\n",
      "73.  кемпинг .................. 351\n",
      "74.  будапешт ................. 347\n",
      "75.  брест .................... 346\n",
      "76.  италия ................... 345\n",
      "77.  симферополь .............. 345\n",
      "78.  львов .................... 341\n",
      "79.  париж .................... 341\n",
      "80.  supermarket .............. 339\n",
      "81.  кемер .................... 339\n",
      "82.  сочи ..................... 339\n",
      "83.  центральный рынок ........ 338\n",
      "84.  остров ................... 337\n",
      "85.  витебск .................. 326\n",
      "86.  омск ..................... 326\n",
      "87.  польша ................... 321\n",
      "88.  венеция .................. 319\n",
      "89.  керчь .................... 317\n",
      "90.  азс ...................... 317\n",
      "91.  петрозаводск ............. 316\n",
      "92.  белгород ................. 315\n",
      "93.  греция ................... 313\n",
      "94.  судак .................... 313\n",
      "95.  стамбул .................. 313\n",
      "96.  гомель ................... 311\n",
      "97.  анталья .................. 310\n",
      "98.  вильнюс .................. 310\n",
      "99.  ресторан ................. 309\n",
      "100.  торговый ................. 309\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(top_100_rus_queries, range(1, 101)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП-100 запросов на английском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  hotel .................... 6943\n",
      "2.  where to eat ............. 6474\n",
      "3.  sights ................... 3342\n",
      "4.  groceries ................ 3189\n",
      "5.  supermarket .............. 1747\n",
      "6.  mcdonalds ................ 1591\n",
      "7.  shopping ................. 1557\n",
      "8.  airport .................. 1379\n",
      "9.  atm ...................... 1374\n",
      "10.  transport ................ 1126\n",
      "11.  carrefour ................ 1082\n",
      "12.  via ...................... 1054\n",
      "13.  san ...................... 1038\n",
      "14.  lidl ..................... 971\n",
      "15.  santa .................... 958\n",
      "16.  porto .................... 930\n",
      "17.  pristina ................. 908\n",
      "18.  starbucks ................ 889\n",
      "19.  gas ...................... 862\n",
      "20.  arkhangai ................ 852\n",
      "21.  nightlife ................ 841\n",
      "22.  ulaanbaatar .............. 767\n",
      "23.  the ...................... 752\n",
      "24.  bank ..................... 744\n",
      "25.  mercado .................. 733\n",
      "26.  camping .................. 709\n",
      "27.  достопримечательность .... 695\n",
      "28.  продукты ................. 670\n",
      "29.  market ................... 668\n",
      "30.  petrol ................... 647\n",
      "31.  piazza ................... 644\n",
      "32.  wifi ..................... 642\n",
      "33.  ulaan .................... 631\n",
      "34.  saint .................... 627\n",
      "35.  pharmacy ................. 627\n",
      "36.  airp ..................... 619\n",
      "37.  гостиница ................ 616\n",
      "38.  где поесть ............... 615\n",
      "39.  hospital ................. 614\n",
      "40.  ugiinnuur ................ 579\n",
      "41.  zara ..................... 576\n",
      "42.  parking .................. 567\n",
      "43.  new ...................... 552\n",
      "44.  terhiin .................. 547\n",
      "45.  metro .................... 534\n",
      "46.  plaza .................... 515\n",
      "47.  harhorin ................. 507\n",
      "48.  grand .................... 505\n",
      "49.  toilet ................... 503\n",
      "50.  elsen .................... 501\n",
      "51.  london ................... 492\n",
      "52.  erdenet .................. 485\n",
      "53.  villa .................... 475\n",
      "54.  rue ...................... 474\n",
      "55.  marina ................... 457\n",
      "56.  cafe ..................... 453\n",
      "57.  macdonalds ............... 445\n",
      "58.  calle .................... 444\n",
      "59.  restaurant ............... 433\n",
      "60.  kfc ...................... 428\n",
      "61.  old ...................... 423\n",
      "62.  pizza .................... 414\n",
      "63.  paris .................... 411\n",
      "64.  istanbul ................. 399\n",
      "65.  bulgan ................... 397\n",
      "66.  milan .................... 397\n",
      "67.  museum ................... 375\n",
      "68.  park ..................... 374\n",
      "69.  termini .................. 374\n",
      "70.  barcelona ................ 366\n",
      "71.  ulaan tsutgalan .......... 359\n",
      "72.  outlet ................... 359\n",
      "73.  museo .................... 357\n",
      "74.  bar ...................... 353\n",
      "75.  monte .................... 350\n",
      "76.  mall ..................... 349\n",
      "77.  central .................. 348\n",
      "78.  aeroport ................. 347\n",
      "79.  mount .................... 347\n",
      "80.  camp ..................... 331\n",
      "81.  manila ................... 324\n",
      "82.  bus ...................... 323\n",
      "83.  coffee ................... 305\n",
      "84.  terkh .................... 300\n",
      "85.  santa maria .............. 300\n",
      "86.  tirane ................... 299\n",
      "87.  placa .................... 299\n",
      "88.  entertainment ............ 298\n",
      "89.  holiday inn .............. 293\n",
      "90.  hentii ................... 292\n",
      "91.  walmart .................. 288\n",
      "92.  casa ..................... 284\n",
      "93.  post ..................... 283\n",
      "94.  har ...................... 281\n",
      "95.  food ..................... 277\n",
      "96.  beach .................... 275\n",
      "97.  bus station .............. 275\n",
      "98.  gare ..................... 274\n",
      "99.  royal .................... 271\n",
      "100.  chinatown ................ 270\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(top_100_eng_queries, range(1, 101)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_categories = ['где поесть', 'гостиница', 'продукты', 'достопримечательность', 'wifi', 'транспорт', 'заправка', \\\n",
    "                  'парковка', 'шоппинг', 'банкомат', 'ночная жизнь', 'отдых с детьми', 'банк', 'развлечения', \\\n",
    "                  'больница', 'аптека', 'полиция', 'туалет', 'почта']\n",
    "eng_categories = ['where to eat', 'hotel', 'groceries', 'sights', 'wifi', 'transport', 'gas', 'parking', 'shopping', \\\n",
    "                  'atm', 'nightlife', 'family holiday', 'bank', 'entertainment', 'hospital', 'pharmacy', 'police', \\\n",
    "                  'toilet', 'post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "# Словарь встречаемости категорий, при этом из общего словаря удаляем все категории\n",
    "for cat in zip(rus_categories, eng_categories):\n",
    "    cat_dict[(cat[0], 'ru')] = frequency_dict.pop((cat[0], 'ru'))\n",
    "    cat_dict[(cat[1], 'en')] = frequency_dict.pop((cat[1], 'en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дальше вся та же обработка, что была с исходным словарём\n",
    "\n",
    "sorted_cat_frequency = sorted(cat_dict.items(), key=operator.itemgetter(1))\n",
    "\n",
    "cat_ru_frequency = []\n",
    "cat_eng_frequency = []\n",
    "\n",
    "for i in range(len(sorted_cat_frequency))[::-1]:\n",
    "    if sorted_cat_frequency[i][0][1] == 'en':\n",
    "        cat_eng_frequency.append((sorted_cat_frequency[i][0][0], sorted_cat_frequency[i][1]))\n",
    "    else:\n",
    "        cat_ru_frequency.append((sorted_cat_frequency[i][0][0], sorted_cat_frequency[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_without_cats_frequency = sorted(frequency_dict.items(), key=operator.itemgetter(1))\n",
    "\n",
    "without_cats_ru_frequency = []\n",
    "without_cats_eng_frequency = []\n",
    "\n",
    "for i in range(len(sorted_without_cats_frequency))[::-1]:\n",
    "    if sorted_without_cats_frequency[i][0][1] == 'en':\n",
    "        without_cats_eng_frequency.append((sorted_without_cats_frequency[i][0][0], sorted_without_cats_frequency[i][1]))\n",
    "    else:\n",
    "        without_cats_ru_frequency.append((sorted_without_cats_frequency[i][0][0], sorted_without_cats_frequency[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_rus_queries_without_cats = without_cats_ru_frequency[:100]\n",
    "top_100_eng_queries_without_cats = without_cats_eng_frequency[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП категорий на русском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  достопримечательность .... 11207\n",
      "2.  где поесть ............... 10187\n",
      "3.  продукты ................. 8222\n",
      "4.  гостиница ................ 6272\n",
      "5.  заправка ................. 4261\n",
      "6.  шоппинг .................. 3109\n",
      "7.  аптека ................... 1658\n",
      "8.  транспорт ................ 1640\n",
      "9.  банкомат ................. 1489\n",
      "10.  туалет ................... 1053\n",
      "11.  парковка ................. 1018\n",
      "12.  банк ..................... 816\n",
      "13.  ночная жизнь ............. 795\n",
      "14.  отдых с детьми ........... 752\n",
      "15.  развлечения .............. 595\n",
      "16.  почта .................... 491\n",
      "17.  wifi ..................... 486\n",
      "18.  больница ................. 445\n",
      "19.  полиция .................. 150\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(cat_ru_frequency, range(1, 20)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП категорий на английском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  hotel .................... 6943\n",
      "2.  where to eat ............. 6474\n",
      "3.  sights ................... 3342\n",
      "4.  groceries ................ 3189\n",
      "5.  shopping ................. 1557\n",
      "6.  atm ...................... 1374\n",
      "7.  transport ................ 1126\n",
      "8.  gas ...................... 862\n",
      "9.  nightlife ................ 841\n",
      "10.  bank ..................... 744\n",
      "11.  wifi ..................... 642\n",
      "12.  pharmacy ................. 627\n",
      "13.  hospital ................. 614\n",
      "14.  parking .................. 567\n",
      "15.  toilet ................... 503\n",
      "16.  entertainment ............ 298\n",
      "17.  post ..................... 283\n",
      "18.  family holiday ........... 263\n",
      "19.  police ................... 195\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(cat_eng_frequency, range(1, 20)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП-100 запросов на русском без категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  москва ................... 1594\n",
      "2.  аэропорт ................. 1415\n",
      "3.  метро .................... 1413\n",
      "4.  минск .................... 1254\n",
      "5.  супермаркет .............. 1204\n",
      "6.  автовокзал ............... 1182\n",
      "7.  рынок .................... 1142\n",
      "8.  магазин .................. 1124\n",
      "9.  макдональдс .............. 932\n",
      "10.  улица .................... 862\n",
      "11.  музей .................... 747\n",
      "12.  вокзал ................... 721\n",
      "13.  пляж ..................... 705\n",
      "14.  самара ................... 665\n",
      "15.  площадь .................. 623\n",
      "16.  торговый центр ........... 590\n",
      "17.  прага .................... 568\n",
      "18.  парк ..................... 561\n",
      "19.  крым ..................... 548\n",
      "20.  санкт петербург .......... 539\n",
      "21.  кафе ..................... 538\n",
      "22.  озеро .................... 533\n",
      "23.  lidl ..................... 505\n",
      "24.  киев ..................... 503\n",
      "25.  краснодар ................ 494\n",
      "26.  отель .................... 476\n",
      "27.  водопад .................. 462\n",
      "28.  халкидики ................ 460\n",
      "29.  волгоград ................ 455\n",
      "30.  тбилиси .................. 450\n",
      "31.  одесса ................... 450\n",
      "32.  аквапарк ................. 449\n",
      "33.  санкт .................... 443\n",
      "34.  ленина ................... 439\n",
      "35.  казань ................... 415\n",
      "36.  парикмахерская ........... 409\n",
      "37.  ростов ................... 409\n",
      "38.  воронеж .................. 406\n",
      "39.  севастополь .............. 406\n",
      "40.  варшава .................. 405\n",
      "41.  рим ...................... 394\n",
      "42.  батуми ................... 393\n",
      "43.  россия ................... 390\n",
      "44.  аланья ................... 383\n",
      "45.  ялта ..................... 382\n",
      "46.  куст ..................... 382\n",
      "47.  турция ................... 381\n",
      "48.  барселона ................ 381\n",
      "49.  калининград .............. 372\n",
      "50.  ташкент .................. 371\n",
      "51.  кирова ................... 371\n",
      "52.  зоопарк .................. 370\n",
      "53.  екатеринбург ............. 359\n",
      "54.  обмен валюты ............. 358\n",
      "55.  кемпинг .................. 351\n",
      "56.  будапешт ................. 347\n",
      "57.  брест .................... 346\n",
      "58.  италия ................... 345\n",
      "59.  симферополь .............. 345\n",
      "60.  львов .................... 341\n",
      "61.  париж .................... 341\n",
      "62.  supermarket .............. 339\n",
      "63.  кемер .................... 339\n",
      "64.  сочи ..................... 339\n",
      "65.  центральный рынок ........ 338\n",
      "66.  остров ................... 337\n",
      "67.  витебск .................. 326\n",
      "68.  омск ..................... 326\n",
      "69.  польша ................... 321\n",
      "70.  венеция .................. 319\n",
      "71.  керчь .................... 317\n",
      "72.  азс ...................... 317\n",
      "73.  петрозаводск ............. 316\n",
      "74.  белгород ................. 315\n",
      "75.  греция ................... 313\n",
      "76.  судак .................... 313\n",
      "77.  стамбул .................. 313\n",
      "78.  гомель ................... 311\n",
      "79.  анталья .................. 310\n",
      "80.  вильнюс .................. 310\n",
      "81.  ресторан ................. 309\n",
      "82.  торговый ................. 309\n",
      "83.  кипр ..................... 308\n",
      "84.  челябинск ................ 308\n",
      "85.  берлин ................... 299\n",
      "86.  новосибирск .............. 298\n",
      "87.  беларусь ................. 296\n",
      "88.  рига ..................... 296\n",
      "89.  анапа .................... 295\n",
      "90.  кишинев .................. 293\n",
      "91.  будва .................... 292\n",
      "92.  мыс ...................... 290\n",
      "93.  ростов на дону ........... 282\n",
      "94.  жд вокзал ................ 282\n",
      "95.  столовая ................. 281\n",
      "96.  грузия ................... 281\n",
      "97.  сан ...................... 280\n",
      "98.  mcdonald ................. 273\n",
      "99.  советская ................ 272\n",
      "100.  ашан ..................... 269\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(top_100_rus_queries_without_cats, range(1, 101)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ТОП-100 запросов на английском без категорий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  supermarket .............. 1747\n",
      "2.  mcdonalds ................ 1591\n",
      "3.  airport .................. 1379\n",
      "4.  carrefour ................ 1082\n",
      "5.  via ...................... 1054\n",
      "6.  san ...................... 1038\n",
      "7.  lidl ..................... 971\n",
      "8.  santa .................... 958\n",
      "9.  porto .................... 930\n",
      "10.  pristina ................. 908\n",
      "11.  starbucks ................ 889\n",
      "12.  arkhangai ................ 852\n",
      "13.  ulaanbaatar .............. 767\n",
      "14.  the ...................... 752\n",
      "15.  mercado .................. 733\n",
      "16.  camping .................. 709\n",
      "17.  достопримечательность .... 695\n",
      "18.  продукты ................. 670\n",
      "19.  market ................... 668\n",
      "20.  petrol ................... 647\n",
      "21.  piazza ................... 644\n",
      "22.  ulaan .................... 631\n",
      "23.  saint .................... 627\n",
      "24.  airp ..................... 619\n",
      "25.  гостиница ................ 616\n",
      "26.  где поесть ............... 615\n",
      "27.  ugiinnuur ................ 579\n",
      "28.  zara ..................... 576\n",
      "29.  new ...................... 552\n",
      "30.  terhiin .................. 547\n",
      "31.  metro .................... 534\n",
      "32.  plaza .................... 515\n",
      "33.  harhorin ................. 507\n",
      "34.  grand .................... 505\n",
      "35.  elsen .................... 501\n",
      "36.  london ................... 492\n",
      "37.  erdenet .................. 485\n",
      "38.  villa .................... 475\n",
      "39.  rue ...................... 474\n",
      "40.  marina ................... 457\n",
      "41.  cafe ..................... 453\n",
      "42.  macdonalds ............... 445\n",
      "43.  calle .................... 444\n",
      "44.  restaurant ............... 433\n",
      "45.  kfc ...................... 428\n",
      "46.  old ...................... 423\n",
      "47.  pizza .................... 414\n",
      "48.  paris .................... 411\n",
      "49.  istanbul ................. 399\n",
      "50.  bulgan ................... 397\n",
      "51.  milan .................... 397\n",
      "52.  museum ................... 375\n",
      "53.  park ..................... 374\n",
      "54.  termini .................. 374\n",
      "55.  barcelona ................ 366\n",
      "56.  ulaan tsutgalan .......... 359\n",
      "57.  outlet ................... 359\n",
      "58.  museo .................... 357\n",
      "59.  bar ...................... 353\n",
      "60.  monte .................... 350\n",
      "61.  mall ..................... 349\n",
      "62.  central .................. 348\n",
      "63.  aeroport ................. 347\n",
      "64.  mount .................... 347\n",
      "65.  camp ..................... 331\n",
      "66.  manila ................... 324\n",
      "67.  bus ...................... 323\n",
      "68.  coffee ................... 305\n",
      "69.  terkh .................... 300\n",
      "70.  santa maria .............. 300\n",
      "71.  tirane ................... 299\n",
      "72.  placa .................... 299\n",
      "73.  holiday inn .............. 293\n",
      "74.  hentii ................... 292\n",
      "75.  walmart .................. 288\n",
      "76.  casa ..................... 284\n",
      "77.  har ...................... 281\n",
      "78.  food ..................... 277\n",
      "79.  beach .................... 275\n",
      "80.  bus station .............. 275\n",
      "81.  gare ..................... 274\n",
      "82.  royal .................... 271\n",
      "83.  chinatown ................ 270\n",
      "84.  улаан цутгалан ........... 269\n",
      "85.  dadal .................... 267\n",
      "86.  darkhan .................. 264\n",
      "87.  rome ..................... 264\n",
      "88.  primark .................. 262\n",
      "89.  berlin ................... 262\n",
      "90.  red ...................... 259\n",
      "91.  mac ...................... 258\n",
      "92.  khuvsgul ................. 257\n",
      "93.  victoria ................. 257\n",
      "94.  durres ................... 256\n",
      "95.  ikea ..................... 254\n",
      "96.  bali ..................... 253\n",
      "97.  amsterdam ................ 250\n",
      "98.  skopje ................... 246\n",
      "99.  golden ................... 245\n",
      "100.  tbilisi .................. 243\n"
     ]
    }
   ],
   "source": [
    "for query, i in zip(top_100_eng_queries_without_cats, range(1, 101)):\n",
    "    print(str(i) + '. ', query[0], str('.' * (25 - len(query[0]))), str(query[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
